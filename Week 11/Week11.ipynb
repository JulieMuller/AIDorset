{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "from torch.utils import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=tensorboard.SummaryWriter('runs/experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data= datasets.MNIST(train=True,\n",
    "                           root='data',\n",
    "                           transform=ToTensor(),\n",
    "                           download=True)\n",
    "test_data=datasets.MNIST(train=True,\n",
    "                           root='data',\n",
    "                           transform=ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '5')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[0])\n",
    "plt.title(train_data.targets[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(train_data,\n",
    "                                    batch_size=100,\n",
    "                                    shuffle=True)\n",
    "\n",
    "train_loader=torch.utils.data.DataLoader(test_data,\n",
    "                                    batch_size=100,\n",
    "                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 30568), started 0:47:48 ago. (Use '!kill 30568' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eeb21e180982d64f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eeb21e180982d64f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model\n",
    "#conv() -> relu -> maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "size of input tensor and input format are different.         tensor shape: (3, 392, 242), input_format: NCHW",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mulle\\Desktop\\AIDorset\\Week 11\\Week11.ipynb Cell 8\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m images, targets \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_sample)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m image_grid\u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mmake_grid(images)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m writer\u001b[39m.\u001b[39;49madd_images(\u001b[39m'\u001b[39;49m\u001b[39mSample MNIST\u001b[39;49m\u001b[39m'\u001b[39;49m, image_grid)\n",
      "File \u001b[1;32mc:\\Users\\Mulle\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:695\u001b[0m, in \u001b[0;36mSummaryWriter.add_images\u001b[1;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m workspace\n\u001b[0;32m    693\u001b[0m     img_tensor \u001b[39m=\u001b[39m workspace\u001b[39m.\u001b[39mFetchBlob(img_tensor)\n\u001b[0;32m    694\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_summary(\n\u001b[1;32m--> 695\u001b[0m     image(tag, img_tensor, dataformats\u001b[39m=\u001b[39;49mdataformats), global_step, walltime\n\u001b[0;32m    696\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Mulle\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:545\u001b[0m, in \u001b[0;36mimage\u001b[1;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Outputs a `Summary` protocol buffer with images.\u001b[39;00m\n\u001b[0;32m    520\u001b[0m \u001b[39mThe summary has up to `max_images` summary values containing images. The\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[39mimages are built from `tensor` which must be 3-D with shape `[height, width,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[39m  buffer.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    544\u001b[0m tensor \u001b[39m=\u001b[39m make_np(tensor)\n\u001b[1;32m--> 545\u001b[0m tensor \u001b[39m=\u001b[39m convert_to_HWC(tensor, dataformats)\n\u001b[0;32m    546\u001b[0m \u001b[39m# Do not assume that user passes in values in [0, 255], use data type to detect\u001b[39;00m\n\u001b[0;32m    547\u001b[0m scale_factor \u001b[39m=\u001b[39m _calc_scale_factor(tensor)\n",
      "File \u001b[1;32mc:\\Users\\Mulle\\anaconda3\\envs\\py38\\lib\\site-packages\\torch\\utils\\tensorboard\\_utils.py:99\u001b[0m, in \u001b[0;36mconvert_to_HWC\u001b[1;34m(tensor, input_format)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_to_HWC\u001b[39m(tensor, input_format):  \u001b[39m# tensor: numpy array\u001b[39;00m\n\u001b[0;32m     96\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(input_format)) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m     97\u001b[0m         input_format\n\u001b[0;32m     98\u001b[0m     ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou can not use the same dimension shordhand twice.         input_format: \u001b[39m\u001b[39m{\u001b[39;00minput_format\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 99\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(tensor\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[0;32m    100\u001b[0m         input_format\n\u001b[0;32m    101\u001b[0m     ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msize of input tensor and input format are different. \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m        tensor shape: \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m, input_format: \u001b[39m\u001b[39m{\u001b[39;00minput_format\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m     input_format \u001b[39m=\u001b[39m input_format\u001b[39m.\u001b[39mupper()\n\u001b[0;32m    105\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(input_format) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: size of input tensor and input format are different.         tensor shape: (3, 392, 242), input_format: NCHW"
     ]
    }
   ],
   "source": [
    "data_sample=iter(train_loader)\n",
    "images, targets = next(data_sample)\n",
    "image_grid= torchvision.utils.make_grid(images)\n",
    "writer.add_images('Sample MNIST', image_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class mnist_cnn(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(mnist_cnn, self).__init()\n",
    "\n",
    "    self.conv_1=nn.Sequential(\n",
    "        nn.Conv2D(\n",
    "            in_channels=1,\n",
    "            out_channels=16,\n",
    "            kernel_size=5,\n",
    "            stride=1,\n",
    "            padding=2\n",
    "        ),\n",
    "        nn.Relu(),\n",
    "        nn.MaxPool2d(kernel_size=2)\n",
    "    )\n",
    "\n",
    "    self.conv_2=nn.Squential(\n",
    "        nn.Conv2D(16,32,5,1,2),\n",
    "        nn.Relu(),\n",
    "        nn.MaxPool2d(2)\n",
    "\n",
    "    )\n",
    "\n",
    "    self.linear_1=nn.Linear(32*7*7,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "      x_1 = self.conv_1(x)\n",
    "      x_2 = self.conv_2(x_1)\n",
    "      x=x.view(x.size(0),-1)\n",
    "      out=self.Linear(x_2)\n",
    "\n",
    "      return out,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '_mnist_cnn__init'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mulle\\Desktop\\AIDorset\\Week 11\\Week11.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m=\u001b[39m mnist_cnn()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m writer\u001b[39m.\u001b[39madd\n",
      "\u001b[1;32mc:\\Users\\Mulle\\Desktop\\AIDorset\\Week 11\\Week11.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   \u001b[39msuper\u001b[39;49m(mnist_cnn, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m__init()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_1\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       nn\u001b[39m.\u001b[39mConv2D(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m           in_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m       nn\u001b[39m.\u001b[39mMaxPool2d(kernel_size\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_2\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mSquential(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m       nn\u001b[39m.\u001b[39mConv2D(\u001b[39m16\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m       nn\u001b[39m.\u001b[39mRelu(),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m       nn\u001b[39m.\u001b[39mMaxPool2d(\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X12sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m   )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'super' object has no attribute '_mnist_cnn__init'"
     ]
    }
   ],
   "source": [
    "model= mnist_cnn()\n",
    "print(model)\n",
    "\n",
    "writer.add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Mulle\\Desktop\\AIDorset\\Week 11\\Week11.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#define loss function and optimizer\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m loss_func \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mulle/Desktop/AIDorset/Week%2011/Week11.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#define loss function and optimizer\n",
    "from torch.autograd import Variable\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n",
    "#trainin loops\n",
    "epochs = 5\n",
    "model.train()\n",
    "for e in range(epochs): #loop over the nmber of epochs\n",
    "    running_loss = 0.0\n",
    "    for i in (images, labels) in enumerate(train_loader): #loop over batch size = 100\n",
    "        b_x = Variable(images)\n",
    "        b_y = Variable(labels)\n",
    "\n",
    "out = model(b_x)[0]\n",
    "loss = loss_func(out, b_y)\n",
    "running_loss += loss \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
